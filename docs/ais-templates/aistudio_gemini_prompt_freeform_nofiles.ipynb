{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/younaniskander/-Predicting-of-a-Restaurant-/blob/main/docs/ais-templates/aistudio_gemini_prompt_freeform_nofiles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2023 Google LLC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKwyTRdwB8aW"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RXInneX6xx7c"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q \"google-generativeai>=0.8.2\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "# تعيين API Key مباشرة\n",
        "api_key = \"AIzaSyCuJF7KgGtQQEY4ON-FcBdacFel9KDLXB0\"\n",
        "\n",
        "# تهيئة نموذج Gemini\n",
        "genai.configure(api_key=api_key)\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")"
      ],
      "metadata": {
        "id": "eCIu06Wuwwr6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "kWIuwKG2_oWE",
        "outputId": "e5511207-0ebc-4083-e5b0-dcfb3c8e7f29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "السؤال: الفراخ عندي مريض؟\n",
            "الرد: أنا آسف، لكنني لست طبيباً بيطرياً ولا أستطيع تقديم نصائح طبية للدواجن.  إذا كانت فراخك مريضة، أنصحك بالاتصال بطبيب بيطري أو خبير في تربية الدواجن للحصول على المساعدة.  يمكنهم تشخيص المشكلة وتقديم العلاج المناسب.  يجب عليك وصف أعراض مرض الفراخ بدقة للطبيب البيطري، مثل:\n",
            "\n",
            "* **نوع الفراخ:** (صغيرة، كبيرة، سلالة محددة...)\n",
            "* **أعراض المرض:** (إسهال، سعال، فقدان الشهية، ضعف، تورم، تغير في لون البراز...)\n",
            "* **متى بدأت الأعراض؟**\n",
            "* **ما هي ظروف تربيتها؟** (نوع الطعام، مكان التربية، درجة الحرارة، التهوية...)\n",
            "* **هل هناك فراخ أخرى مريضة\n",
            "\n",
            "السؤال: ما هي أفضل أنواع السيارات؟\n",
            "الرد: عذرًا، أنا متخصص في مجال تربية الدواجن ومعدلات التربية فقط. كيف يمكنني مساعدتك في هذا المجال؟\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import google.generativeai as genai\n",
        "import json\n",
        "\n",
        "# تعيين API Key مباشرة\n",
        "api_key = \"AIzaSyCuJF7KgGtQQEY4ON-FcBdacFel9KDLXB0\"  # استبدل هذا بـ API Key الخاص بك\n",
        "\n",
        "# تحميل البيانات من ملف JSON\n",
        "with open('data.json', 'r', encoding='utf-8') as file:\n",
        "    training_data = json.load(file)\n",
        "\n",
        "# قائمة الكلمات الدالة\n",
        "keywords = [\"دواجن\", \"تربية\", \"علف\", \"معدلات\", \"إنتاج\", \"فراخ\", \"بيض\", \"لحوم\", \"أمراض\", \"تحصين\"]\n",
        "\n",
        "# تحويل البيانات إلى تنسيق مناسب لـ Gemini\n",
        "contents = [{\"role\": \"user\", \"parts\": [{\"text\": f\"Q: {item['question']}\\nA: {item['answer']}\"}]} for item in training_data]\n",
        "\n",
        "# تهيئة نموذج Gemini\n",
        "genai.configure(api_key=api_key)\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")\n",
        "\n",
        "# تخصيص إعدادات النموذج\n",
        "generation_config = {\n",
        "    \"temperature\": 0.5,  # التحكم في الإبداعية (0 = دقيق، 1 = مبدع)\n",
        "    \"max_output_tokens\": 200,  # الحد الأقصى لعدد الكلمات في الرد\n",
        "}\n",
        "\n",
        "# إعدادات الأمان (تم تغييرها لحظر المحتوى المسيء وخطاب الكراهية)\n",
        "safety_settings = {\n",
        "    \"harassment\": \"BLOCK_MEDIUM_AND_ABOVE\",  # حظر المحتوى المسيء متوسط الخطورة وأعلى\n",
        "    \"hate_speech\": \"BLOCK_MEDIUM_AND_ABOVE\",  # حظر خطاب الكراهية متوسط الخطورة وأعلى\n",
        "}\n",
        "\n",
        "# بدء محادثة مع النموذج\n",
        "chat = model.start_chat(history=contents)\n",
        "\n",
        "def is_related_to_poultry(question):\n",
        "    \"\"\"\n",
        "    تحقق مما إذا كان السؤال متعلقًا بتربية الدواجن باستخدام الكلمات الدالة.\n",
        "    \"\"\"\n",
        "    for keyword in keywords:\n",
        "        if keyword in question:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def get_response(question):\n",
        "    \"\"\"\n",
        "    الحصول على رد من الشات بوت أو رسالة تفيد بأن السؤال خارج النطاق.\n",
        "    \"\"\"\n",
        "    if is_related_to_poultry(question):\n",
        "        response = chat.send_message(\n",
        "            question,\n",
        "            generation_config=generation_config,\n",
        "            safety_settings=safety_settings,\n",
        "            stream=False\n",
        "        )\n",
        "        return response.text\n",
        "    else:\n",
        "        return \"عذرًا، أنا متخصص في مجال تربية الدواجن ومعدلات التربية فقط. كيف يمكنني مساعدتك في هذا المجال؟\"\n",
        "\n",
        "# مثال لسؤال متعلق بالدواجن\n",
        "question1 = \"الفراخ عندي مريض؟\"\n",
        "response1 = get_response(question1)\n",
        "print(f\"السؤال: {question1}\\nالرد: {response1}\\n\")\n",
        "\n",
        "# مثال لسؤال خارج نطاق الدواجن\n",
        "question2 = \"ما هي أفضل أنواع السيارات؟\"\n",
        "response2 = get_response(question2)\n",
        "print(f\"السؤال: {question2}\\nالرد: {response2}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import json\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import os\n",
        "\n",
        "# تعيين API Key مباشرشك  # استبدل هذا بـ API Key الخاص بك\n",
        "\n",
        "# تحميل البيانات من ملف JSON\n",
        "with open('data.json', 'r', encoding='utf-8') as file:\n",
        "    training_data = json.load(file)\n",
        "\n",
        "# قائمة الكلمات الدالة\n",
        "keywords = [\"دواجن\", \"تربية\", \"علف\", \"معدلات\", \"إنتاج\", \"فراخ\", \"بيض\", \"لحوم\", \"أمراض\", \"تحصين\"]\n",
        "\n",
        "# تحويل البيانات إلى تنسيق مناسب لـ Gemini\n",
        "contents = [{\"role\": \"user\", \"parts\": [{\"text\": f\"Q: {item['question']}\\nA: {item['answer']}\"}]} for item in training_data]\n",
        "\n",
        "# تهيئة نموذج Gemini\n",
        "genai.configure(api_key=api_key)\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")\n",
        "\n",
        "# تخصيص إعدادات النموذج\n",
        "generation_config = {\n",
        "    \"temperature\": 0.5,  # التحكم في الإبداعية (0 = دقيق، 1 = مبدع)\n",
        "    \"max_output_tokens\": 200,  # الحد الأقصى لعدد الكلمات في الرد\n",
        "}\n",
        "\n",
        "# إعدادات الأمان\n",
        "safety_settings = {\n",
        "    \"harassment\": \"BLOCK_MEDIUM_AND_ABOVE\",  # حظر المحتوى المسيء متوسط الخطورة وأعلى\n",
        "    \"hate_speech\": \"BLOCK_MEDIUM_AND_ABOVE\",  # حظر خطاب الكراهية متوسط الخطورة وأعلى\n",
        "}\n",
        "\n",
        "# بدء محادثة مع النموذج\n",
        "chat = model.start_chat(history=contents)\n",
        "\n",
        "def load_conversation_history():\n",
        "    \"\"\"\n",
        "    تحميل تاريخ المحادثات من ملف JSON.\n",
        "    \"\"\"\n",
        "    if os.path.exists(\"conversation_history.json\"):\n",
        "        with open(\"conversation_history.json\", \"r\", encoding=\"utf-8\") as file:\n",
        "            return json.load(file)\n",
        "    return []\n",
        "\n",
        "# تحميل تاريخ المحادثات\n",
        "conversation_history = load_conversation_history()\n",
        "\n",
        "# إضافة التفاعلات السابقة إلى تاريخ المحادثة\n",
        "for interaction in conversation_history:\n",
        "    chat.history.append({\n",
        "        \"role\": \"user\",\n",
        "        \"parts\": [{\"text\": interaction[\"question\"]}]\n",
        "    })\n",
        "    chat.history.append({\n",
        "        \"role\": \"model\",\n",
        "        \"parts\": [{\"text\": interaction[\"response\"]}]\n",
        "    })\n",
        "\n",
        "def save_image(image, image_name):\n",
        "    \"\"\"\n",
        "    حفظ الصورة في مجلد محلي وإرجاع مسارها.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(\"images\"):\n",
        "        os.makedirs(\"images\")\n",
        "    image_path = f\"images/{image_name}.png\"\n",
        "    image.save(image_path)\n",
        "    return image_path\n",
        "\n",
        "def save_conversation(question, response, image_path=None):\n",
        "    \"\"\"\n",
        "    حفظ السؤال والرد في ملف JSON.\n",
        "    \"\"\"\n",
        "    conversation = {\n",
        "        \"question\": question,\n",
        "        \"response\": response,\n",
        "        \"image_path\": image_path\n",
        "    }\n",
        "\n",
        "    if not os.path.exists(\"conversation_history.json\"):\n",
        "        with open(\"conversation_history.json\", \"w\", encoding=\"utf-8\") as file:\n",
        "            json.dump([], file)\n",
        "\n",
        "    with open(\"conversation_history.json\", \"r+\", encoding=\"utf-8\") as file:\n",
        "        data = json.load(file)\n",
        "        data.append(conversation)\n",
        "        file.seek(0)\n",
        "        json.dump(data, file, ensure_ascii=False, indent=4)\n",
        "\n",
        "def is_related_to_poultry(question):\n",
        "    \"\"\"\n",
        "    تحقق مما إذا كان السؤال متعلقًا بتربية الدواجن باستخدام الكلمات الدالة أو موجود في data.json.\n",
        "    \"\"\"\n",
        "    # التحقق من الكلمات الدالة\n",
        "    for keyword in keywords:\n",
        "        if keyword in question:\n",
        "            return True\n",
        "\n",
        "    # التحقق من وجود السؤال في data.json\n",
        "    for item in training_data:\n",
        "        if item[\"question\"] in question:\n",
        "            return True\n",
        "\n",
        "    return False\n",
        "\n",
        "def get_response(question, image_url=None):\n",
        "    \"\"\"\n",
        "    الحصول على رد من الشات بوت أو رسالة تفيد بأن السؤال خارج النطاق.\n",
        "    \"\"\"\n",
        "    if is_related_to_poultry(question):\n",
        "        if image_url:\n",
        "            # تحميل الصورة من الرابط\n",
        "            response = requests.get(image_url)\n",
        "            image = Image.open(BytesIO(response.content))\n",
        "\n",
        "            # حفظ الصورة محليًا\n",
        "            image_name = f\"image_{len(os.listdir('images')) + 1}\" if os.path.exists(\"images\") else \"image_1\"\n",
        "            image_path = save_image(image, image_name)\n",
        "\n",
        "            # إرسال الصورة والسؤال إلى النموذج\n",
        "            response = model.generate_content(\n",
        "                [question, image],\n",
        "                generation_config=generation_config,\n",
        "                safety_settings=safety_settings,\n",
        "                stream=False\n",
        "            )\n",
        "        else:\n",
        "            # إرسال السؤال فقط إلى النموذج\n",
        "            response = chat.send_message(\n",
        "                question,\n",
        "                generation_config=generation_config,\n",
        "                safety_settings=safety_settings,\n",
        "                stream=False\n",
        "            )\n",
        "            image_path = None\n",
        "\n",
        "        # حفظ السؤال والرد في ملف JSON\n",
        "        save_conversation(question, response.text, image_path)\n",
        "\n",
        "        return response.text\n",
        "    else:\n",
        "        return \"عذرًا، أنا متخصص في مجال تربية الدواجن ومعدلات التربية فقط. كيف يمكنني مساعدتك في هذا المجال؟\"\n",
        "\n",
        "# رسالة ترحيبية\n",
        "print(\"مرحبًا! أنا شات بوت متخصص في تربية الدواجن. كيف يمكنني مساعدتك؟\")\n",
        "\n",
        "# حلقة تفاعلية\n",
        "asked_questions = set()  # لتجنب الأسئلة المتكررة\n",
        "while True:\n",
        "    question = input(\"أنت: \")\n",
        "\n",
        "    # إنهاء المحادثة إذا قال المستخدم \"شكرًا\"\n",
        "    if \"شكرا\" in question or \"thank you\" in question.lower():\n",
        "        print(\"الشات بوت: على الرحب والسعة! إذا كان لديك المزيد من الأسئلة، فلا تتردد في السؤال.\")\n",
        "        break\n",
        "\n",
        "    # تجنب الأسئلة المتكررة\n",
        "    if question in asked_questions:\n",
        "        print(\"الشات بوت: لقد سألت هذا السؤال مسبقًا. هل لديك سؤال آخر؟\")\n",
        "        continue\n",
        "\n",
        "    # إضافة السؤال إلى قائمة الأسئلة المطروحة\n",
        "    asked_questions.add(question)\n",
        "\n",
        "    # الحصول على الرد\n",
        "    response = get_response(question)\n",
        "    print(f\"الشات بوت: {response}\\n\")"
      ],
      "metadata": {
        "id": "JdEMr2tXATjB",
        "outputId": "0f63891b-d4ca-4a62-f7a5-e6ff104a88c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "مرحبًا! أنا شات بوت متخصص في تربية الدواجن. كيف يمكنني مساعدتك؟\n",
            "أنت: انت شايف اي\n",
            "الشات بوت: عذرًا، أنا متخصص في مجال تربية الدواجن ومعدلات التربية فقط. كيف يمكنني مساعدتك في هذا المجال؟\n",
            "\n",
            "أنت: ما هو تحصين الفراخ\n",
            "الشات بوت: تحصين الفراخ هو عملية إعطاء الدجاج لقاحات لحمايتها من الأمراض المختلفة.  هذه اللقاحات تحفز جهاز المناعة لديها لإنتاج أجسام مضادة ضد مسببات الأمراض، مما يجعلها أكثر مقاومة للإصابة بالمرض أو يقلل من شدة المرض إذا أصيبت.\n",
            "\n",
            "تختلف أنواع اللقاحات المستخدمة حسب المرض المستهدف وعمر الدجاجة،  وتشمل بعض الأمراض الشائعة التي يتم تحصين الدجاج ضدها:\n",
            "\n",
            "* **مرض نيوتكاسل (داء الطيور):** مرض شديد العدوى يمكن أن يسبب نفوقًا واسعًا في قطعان الدجاج.\n",
            "* **مرض غامبورو (بورسا):** مرض فيروسي يصيب الجهاز المناعي للدجاج.\n",
            "* **مرض التهاب القصبة الهوائية المعدي:** مرض تنفسي معدٍ.\n",
            "\n",
            "\n",
            "أنت: شكرا\n",
            "الشات بوت: على الرحب والسعة! إذا كان لديك المزيد من الأسئلة، فلا تتردد في السؤال.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7zAD69vE92b"
      },
      "source": [
        "## Call `generate_content`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "LB2LxPmAB95V",
        "outputId": "d76c7592-0ca9-4ad6-8f5f-a528d0246801",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "argument of type 'GenerativeModel' is not iterable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-0af918783a87>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Call the model and print the response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mgemini\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerativeModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m response = gemini.generate_content(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/generativeai/generative_models.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name, safety_settings, generation_config, tools, tool_config, system_instruction)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0msystem_instruction\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcontent_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mContentType\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     ):\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m             \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"models/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: argument of type 'GenerativeModel' is not iterable"
          ]
        }
      ],
      "source": [
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "# Call the model and print the response.\n",
        "gemini = genai.GenerativeModel(model_name=model)\n",
        "\n",
        "response = gemini.generate_content(\n",
        "    contents,\n",
        "    generation_config=generation_config,\n",
        "    safety_settings=safety_settings,\n",
        "    stream=stream,\n",
        ")\n",
        "\n",
        "display(Markdown(response.text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c9d345e9868"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://ai.google.dev/gemini-api/docs\"><img src=\"https://ai.google.dev/static/site-assets/images/docs/notebook-site-button.png\" height=\"32\" width=\"32\" />Docs on ai.google.dev</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/google-gemini/cookbook/blob/main/quickstarts\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />More notebooks in the Cookbook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Tce3stUlHN0L"
      ],
      "name": "aistudio_gemini_prompt_freeform_nofiles.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}